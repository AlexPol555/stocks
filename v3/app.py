
# app_with_scheduler.py ‚Äî Streamlit app with daily scheduler (00:00) and manual API update
import streamlit as st
import pandas as pd
import numpy as np
import database
import logging
import os
import sqlite3

from typing import Optional

logger = logging.getLogger(__name__)

# –ø–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å matplotlib –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ (—É—Å—Ç–æ–π—á–∏–≤–∞—è –∑–∞–≥–ª—É—à–∫–∞)
try:
    import matplotlib.pyplot as plt
except Exception as _e:
    plt = None
    logger.warning("matplotlib –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", _e)

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
from populate_database import bulk_populate_database_from_csv, incremental_populate_database_from_csv
from stock_analyzer import StockAnalyzer
from auto_update import auto_update_all_tickers, normalize_ticker, update_missing_market_data
from visualization import plot_daily_analysis, plot_stock_analysis, plot_grafik_candle_days
from indicators import get_calculated_data, clear_get_calculated_data
from orders import create_order

# –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
from scheduler import start_daily_midnight

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π", layout="wide")

# guarded import –¥–ª—è st_aggrid ‚Äî –µ—Å–ª–∏ –ø–∞–∫–µ—Ç –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback (st.dataframe)
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode
    ST_AGGRID_AVAILABLE = True
except Exception as _e:
    ST_AGGRID_AVAILABLE = False
    logger.warning("st_aggrid –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", _e)

    # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥–ª—É—à–∫–∞: –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å DataFrame —á–µ—Ä–µ–∑ st.dataframe –∏ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å selected_rows
    def AgGrid(df, gridOptions=None, height=400, fit_columns_on_grid_load=True, **kwargs):
        st.dataframe(df)
        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø–æ—Ö–æ–∂—É—é –Ω–∞ AgGrid response
        return {"selected_rows": []}

    class GridOptionsBuilder:
        def __init__(self, df=None):
            self.df = df
            self._opts = {}

        @staticmethod
        def from_dataframe(df):
            return GridOptionsBuilder(df)

        def configure_selection(self, **kwargs):
            self._opts['selection'] = kwargs
            return self

        def build(self):
            return self._opts

    GridUpdateMode = type("GridUpdateMode", (), {"SELECTION_CHANGED": None})
    DataReturnMode = type("DataReturnMode", (), {"FILTERED_AND_SORTED": None})

# –§—É–Ω–∫—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–∞—Å—á—ë—Ç–æ–≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
def get_calculated_data_cached(_conn):
    data = get_calculated_data(_conn)
    return data

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –ë–î, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—è —Ä–∞–∑–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–π –≤ –º–æ–¥—É–ª–µ database
def open_database_connection():
    for name in ("get_connection", "get_conn", "get_connection"):
        if hasattr(database, name):
            try:
                return getattr(database, name)()
            except TypeError:
                try:
                    return getattr(database, name)(None)
                except Exception:
                    continue
            except Exception as e:
                logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ database.%s: %s", name, e)
    if hasattr(database, "DB_PATH"):
        path = getattr(database, "DB_PATH")
        try:
            return sqlite3.connect(path, check_same_thread=False)
        except Exception as e:
            logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ DB_PATH %s: %s", path, e)
    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥—É–ª—å database.")

# --- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ë–î (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ debug / sidebar) ---
def db_health_check(conn):
    with conn:
        def q(sql, params=()):
            try:
                return pd.read_sql_query(sql, conn, params=params)
            except Exception as e:
                return f"SQL error: {e}"

        st.subheader("–¢–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ")
        tables = q("SELECT name FROM sqlite_master WHERE type='table';")
        st.write(tables)

        st.subheader("Counts")
        for t in ['companies','daily_data','metrics','company_parameters']:
            try:
                cnt = pd.read_sql_query(f"SELECT COUNT(*) AS cnt FROM {t};", conn).iloc[0]['cnt']
            except Exception:
                cnt = "no table"
            st.write(f"{t}: {cnt}")

        st.subheader("Sample companies")
        st.write(q("SELECT * FROM companies LIMIT 10;"))

        st.subheader("Sample daily_data")
        st.write(q("SELECT * FROM daily_data LIMIT 10;"))

        st.subheader("Sample metrics")
        st.write(q("SELECT * FROM metrics LIMIT 10;"))

        st.subheader("Join sample (daily_data <-> metrics)")
        st.write(q("""
            SELECT dd.company_id, dd.date, m.metric_type
            FROM daily_data dd
            JOIN metrics m ON dd.company_id = m.company_id AND dd.date = m.date
            LIMIT 20;
        """))

# --- –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ selected_rows –∏–∑ –æ—Ç–≤–µ—Ç–∞ AgGrid ---
def _extract_selected_rows(grid_response):
    try:
        if isinstance(grid_response, dict):
            return grid_response.get("selected_rows", grid_response.get("data", None))
        if hasattr(grid_response, "selected_rows"):
            return getattr(grid_response, "selected_rows")
        if hasattr(grid_response, "data"):
            return getattr(grid_response, "data")
        if isinstance(grid_response, list):
            return grid_response
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ selected_rows: %s", e)
    return None

# ====== API UPDATE JOB (—Ä—É—á–Ω–æ–π –∏ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é) ======
def _read_api_key():
    return st.secrets.get("TINKOFF_API_KEY") or st.secrets.get("tinkoff", {}).get("api_key") or os.getenv("TINKOFF_API_KEY")

def run_api_update_job(full_update=True):
    """
    –û—Ç–¥–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –∫–æ–Ω–Ω–µ–∫—Ç, —Å–æ–∑–¥–∞—ë—Ç analyzer –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –ø–æ –∫–Ω–æ–ø–∫–µ, —Ç–∞–∫ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º –≤ 00:00.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–æ–≥–æ–≤.
    """
    try:
        job_conn = open_database_connection()
        job_analyzer = StockAnalyzer(_read_api_key(), db_conn=job_conn)
        logs = auto_update_all_tickers(job_analyzer, job_conn, full_update=full_update)
        job_conn.close()
        return logs
    except Exception as e:
        return [f"–û—à–∏–±–∫–∞ –≤ run_api_update_job: {e}"]

@st.cache_resource
def init_daily_scheduler():
    """
    –°–æ–∑–¥–∞—ë—Ç –µ–¥–∏–Ω—ã–π —Ñ–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–∑—ã–≤–∞–µ—Ç –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 00:00 (Europe/Stockholm).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å {thread, stop_event, get_state}.
    """
    def _job():
        # –í —Ñ–æ–Ω–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º Streamlit API; —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        _ = run_api_update_job(full_update=False)

    th, stop_event, get_state = start_daily_midnight(_job, tz="Europe/Stockholm")
    return {"thread": th, "stop_event": stop_event, "get_state": get_state}

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ---
def main_page(conn, analyzer, api_key):
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    df_all = get_calculated_data_cached(conn)
    st.button("–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à", on_click=clear_get_calculated_data)

    if df_all is None or df_all.empty:
        st.info("–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –ø—É—Å—Ç—ã.")
        return

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: –ø–æ –¥–∞—Ç–µ, –ø–æ —Ç–∏–∫–µ—Ä—É –∏–ª–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    unique_dates = sorted(list(df_all["date"].unique()), reverse=True)
    tickers = df_all["contract_code"].unique()
    filter_type = st.sidebar.radio("–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ:", ("–ü–æ –¥–∞—Ç–µ", "–ü–æ —Ç–∏–∫–µ—Ä—É", "–ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"))
    if filter_type == "–ü–æ –¥–∞—Ç–µ":
        selected_date = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É", unique_dates)
        filtered_df = df_all[df_all["date"] == selected_date].copy()
    elif filter_type == "–ü–æ —Ç–∏–∫–µ—Ä—É":
        selected_ticker = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–∫–µ—Ä", tickers)
        filtered_df = df_all[df_all["contract_code"] == selected_ticker].copy()
    else:
        filtered_df = df_all.copy()

    col1, col2, col3, col4 = st.columns(4)
    adaptive_buy = col1.checkbox("Adaptive Buy Signal", value=True)
    adaptive_sell = col2.checkbox("Adaptive Sell Signal", value=True)
    new_adaptive_buy = col3.checkbox("New Adaptive Buy Signal", value=True)
    new_adaptive_sell = col4.checkbox("New Adaptive Sell Signal", value=True)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ mask (–±–µ–∑ –±—É–ª–µ–≤–æ–π –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç–∏)
    mask = pd.Series(False, index=filtered_df.index)
    if adaptive_buy and 'Adaptive_Buy_Signal' in filtered_df.columns:
        mask |= (filtered_df['Adaptive_Buy_Signal'] == 1)
    if adaptive_sell and 'Adaptive_Sell_Signal' in filtered_df.columns:
        mask |= (filtered_df['Adaptive_Sell_Signal'] == 1)
    if new_adaptive_buy and 'New_Adaptive_Buy_Signal' in filtered_df.columns:
        mask |= (filtered_df['New_Adaptive_Buy_Signal'] == 1)
    if new_adaptive_sell and 'New_Adaptive_Sell_Signal' in filtered_df.columns:
        mask |= (filtered_df['New_Adaptive_Sell_Signal'] == 1)

    if mask.any():
        filtered_df = filtered_df[mask]
    else:
        filtered_df = filtered_df.copy()

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AgGrid
    gb = GridOptionsBuilder.from_dataframe(filtered_df)
    try:
        gb.configure_selection(selection_mode="single", use_checkbox=False)
        gridOptions = gb.build()
    except Exception:
        gridOptions = {}

    filtered_df = filtered_df.drop_duplicates()

    grid_response = AgGrid(
        filtered_df,
        gridOptions=gridOptions,
        data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        theme="alpine",
        height=500,
    )

    # --- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ) ---
    selected_rows_raw = _extract_selected_rows(grid_response)

    selected = None
    if selected_rows_raw is not None:
        if isinstance(selected_rows_raw, pd.DataFrame):
            if not selected_rows_raw.empty:
                selected = selected_rows_raw.iloc[0].to_dict()
        elif isinstance(selected_rows_raw, list):
            if len(selected_rows_raw) > 0:
                first = selected_rows_raw[0]
                if isinstance(first, pd.Series):
                    selected = first.to_dict()
                elif isinstance(first, dict):
                    selected = first
                else:
                    try:
                        selected = dict(first)
                    except Exception:
                        selected = None
        elif isinstance(selected_rows_raw, dict):
            selected = selected_rows_raw

    if selected is not None:
        selected_ticker = selected.get("contract_code")
        st.sidebar.write(f"–í—ã–±—Ä–∞–Ω —Ç–∏–∫–µ—Ä: {selected_ticker}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ —á–µ—Ä–µ–∑ database
        try:
            data = database.load_data_from_db(conn)
        except Exception:
            data = pd.DataFrame()
        if data.empty:
            st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±–Ω–æ–≤–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        else:
            filtered_df_full = data[data['contract_code'] == selected_ticker]
            filtered_df_1 = filtered_df_full[filtered_df_full["metric_type"] == "–ò–∑–º–µ–Ω–µ–Ω–∏–µ"]
            filtered_df_2 = filtered_df_full[filtered_df_full["metric_type"] == "–û—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏"]
            colL, colR = st.columns(2)
            with colL:
                st.dataframe(filtered_df_1)
            with colR:
                st.dataframe(filtered_df_2)

        left_col, right_col = st.columns(2)
        with left_col:
            st.markdown("## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞—è–≤–∫–µ")
            st.write(f"**–¢–∏–∫–µ—Ä:** {selected.get('contract_code')}")
            st.write(f"**–î–∞—Ç–∞:** {selected.get('date')}")
            st.write(f"**–¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è:** {selected.get('close')}")
            st.write(f"**RSI:** {selected.get('RSI', 'N/A')}")
            st.write(f"**ATR:** {selected.get('ATR', 'N/A')}")
            st.write(f"**Final_Buy_Signal:** {selected.get('Final_Buy_Signal', 'N/A')}")

            triggered_signals = []
            if selected.get('Signal') == 1:
                triggered_signals.append("–ë–∞–∑–æ–≤—ã–π Buy")
            elif selected.get('Signal') == -1:
                triggered_signals.append("–ë–∞–∑–æ–≤—ã–π Sell")
            if selected.get('Adaptive_Buy_Signal') == 1:
                triggered_signals.append("Adaptive Buy")
            elif selected.get('Adaptive_Sell_Signal') == 1:
                triggered_signals.append("Adaptive Sell")
            if selected.get('New_Adaptive_Buy_Signal') == 1:
                triggered_signals.append("New Adaptive Buy")
            elif selected.get('New_Adaptive_Sell_Signal') == 1:
                triggered_signals.append("New Adaptive Sell")

            st.write(f"**–°—Ä–∞–±–æ—Ç–∞–≤—à–∏–π —Å–∏–≥–Ω–∞–ª:** {', '.join(triggered_signals) if triggered_signals else '–ù–µ—Ç'}")

            if selected.get('Adaptive_Buy_Signal') == 1:
                st.write(f"**Dynamic Profit (Adaptive Buy):** {selected.get('Dynamic_Profit_Adaptive_Buy', 'N/A')}")
                st.write(f"**Exit Date (Adaptive Buy):** {selected.get('Exit_Date_Adaptive_Buy', 'N/A')}")
                st.write(f"**Exit Price (Adaptive Buy):** {selected.get('Exit_Price_Adaptive_Buy', 'N/A')}")
            if selected.get('Adaptive_Sell_Signal') == 1:
                st.write(f"**Dynamic Profit (Adaptive Sell):** {selected.get('Dynamic_Profit_Adaptive_Sell', 'N/A')}")
                st.write(f"**Exit Date (Adaptive Sell):** {selected.get('Exit_Date_Adaptive_Sell', 'N/A')}")
                st.write(f"**Exit Price (Adaptive Sell):** {selected.get('Exit_Price_Adaptive_Sell', 'N/A')}")
            if selected.get('New_Adaptive_Buy_Signal') == 1:
                st.write(f"**Dynamic Profit (New Adaptive Buy):** {selected.get('Dynamic_Profit_New_Adaptive_Buy', 'N/A')}")
                st.write(f"**Exit Date (New Adaptive Buy):** {selected.get('Exit_Date_New_Adaptive_Buy', 'N/A')}")
                st.write(f"**Exit Price (New Adaptive Buy):** {selected.get('Exit_Price_New_Adaptive_Buy', 'N/A')}")
            if selected.get('New_Adaptive_Sell_Signal') == 1:
                st.write(f"**Dynamic Profit (New Adaptive Sell):** {selected.get('Dynamic_Profit_New_Adaptive_Sell', 'N/A')}")
                st.write(f"**Exit Date (New Adaptive Sell):** {selected.get('Exit_Date_New_Adaptive_Sell', 'N/A')}")
                st.write(f"**Exit Price (New Adaptive Sell):** {selected.get('Exit_Price_New_Adaptive_Sell', 'N/A')}")

        with right_col:
            st.write("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞—è–≤–∫–∏ (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)")
    else:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∑–∞—è–≤–∫—É –∏–∑ —Ç–∞–±–ª–∏—Ü—ã.")

    # === –°–≤–æ–¥–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ ===
    df_signals = df_all[
        (df_all.get('Adaptive_Buy_Signal', 0) == 1) |
        (df_all.get('Adaptive_Sell_Signal', 0) == 1) |
        (df_all.get('New_Adaptive_Buy_Signal', 0) == 1) |
        (df_all.get('New_Adaptive_Sell_Signal', 0) == 1)
    ].copy()

    df_signals['Profit_Adaptive_Buy'] = np.where(
        df_signals.get('Adaptive_Buy_Signal', 0) == 1,
        df_signals.get('Dynamic_Profit_Adaptive_Buy', 0),
        0
    )
    df_signals['Profit_Adaptive_Sell'] = np.where(
        df_signals.get('Adaptive_Sell_Signal', 0) == 1,
        df_signals.get('Dynamic_Profit_Adaptive_Sell', 0),
        0
    )
    df_signals['Profit_New_Adaptive_Buy'] = np.where(
        df_signals.get('New_Adaptive_Buy_Signal', 0) == 1,
        df_signals.get('Dynamic_Profit_New_Adaptive_Buy', 0),
        0
    )
    df_signals['Profit_New_Adaptive_Sell'] = np.where(
        df_signals.get('New_Adaptive_Sell_Signal', 0) == 1,
        df_signals.get('Dynamic_Profit_New_Adaptive_Sell', 0),
        0
    )

    summary = df_signals.groupby('contract_code').agg(
        New_Adaptive_Buy_Signal=('New_Adaptive_Buy_Signal', 'sum'),
        New_Adaptive_Sell_Signal=('New_Adaptive_Sell_Signal', 'sum'),
        Adaptive_Buy_Signal=('Adaptive_Buy_Signal', 'sum'),
        Adaptive_Sell_Signal=('Adaptive_Sell_Signal', 'sum'),
        Profit_Adaptive_Buy=('Profit_Adaptive_Buy', 'sum'),
        Profit_Adaptive_Sell=('Profit_Adaptive_Sell', 'sum'),
        Profit_New_Adaptive_Buy=('Profit_New_Adaptive_Buy', 'sum'),
        Profit_New_Adaptive_Sell=('Profit_New_Adaptive_Sell', 'sum')
    ).reset_index()

    st.markdown("## –°–≤–æ–¥–∫–∞ –ø–æ —Å–∏–≥–Ω–∞–ª–∞–º (–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ –ø–æ —Ç–∏–∫–µ—Ä—É)")
    st.write(summary)

    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    if 'date' in df_signals.columns:
        df_signals['date'] = pd.to_datetime(df_signals['date'])
        df_signals['month'] = df_signals['date'].dt.to_period('M')
        df_signals['week'] = df_signals['date'].dt.to_period('W')
        df_signals['year'] = df_signals['date'].dt.to_period('Y')

        summary_by_month = df_signals.groupby('month').agg(
            Adaptive_Buy_Signal=('Adaptive_Buy_Signal', 'sum'),
            Adaptive_Sell_Signal=('Adaptive_Sell_Signal', 'sum'),
            New_Adaptive_Buy_Signal=('New_Adaptive_Buy_Signal', 'sum'),
            New_Adaptive_Sell_Signal=('New_Adaptive_Sell_Signal', 'sum'),
            Profit_Adaptive_Buy=('Profit_Adaptive_Buy', 'sum'),
            Profit_Adaptive_Sell=('Profit_Adaptive_Sell', 'sum'),
            Profit_New_Adaptive_Buy=('Profit_New_Adaptive_Buy', 'sum'),
            Profit_New_Adaptive_Sell=('Profit_New_Adaptive_Sell', 'sum')
        ).reset_index()

        summary_by_week = df_signals.groupby('week').agg(
            Adaptive_Buy_Signal=('Adaptive_Buy_Signal', 'sum'),
            Adaptive_Sell_Signal=('Adaptive_Sell_Signal', 'sum'),
            New_Adaptive_Buy_Signal=('New_Adaptive_Buy_Signal', 'sum'),
            New_Adaptive_Sell_Signal=('New_Adaptive_Sell_Signal', 'sum'),
            Profit_Adaptive_Buy=('Profit_Adaptive_Buy', 'sum'),
            Profit_Adaptive_Sell=('Profit_Adaptive_Sell', 'sum'),
            Profit_New_Adaptive_Buy=('Profit_New_Adaptive_Buy', 'sum'),
            Profit_New_Adaptive_Sell=('Profit_New_Adaptive_Sell', 'sum')
        ).reset_index()

        summary_by_year = df_signals.groupby('year').agg(
            Adaptive_Buy_Signal=('Adaptive_Buy_Signal', 'sum'),
            Adaptive_Sell_Signal=('Adaptive_Sell_Signal', 'sum'),
            New_Adaptive_Buy_Signal=('New_Adaptive_Buy_Signal', 'sum'),
            New_Adaptive_Sell_Signal=('New_Adaptive_Sell_Signal', 'sum'),
            Profit_Adaptive_Buy=('Profit_Adaptive_Buy', 'sum'),
            Profit_Adaptive_Sell=('Profit_Adaptive_Sell', 'sum'),
            Profit_New_Adaptive_Buy=('Profit_New_Adaptive_Buy', 'sum'),
            Profit_New_Adaptive_Sell=('Profit_New_Adaptive_Sell', 'sum')
        ).reset_index()

        st.write("### –°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º:")
        st.write(summary_by_month)
        st.write("### –°–≤–æ–¥–∫–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º:")
        st.write(summary_by_week)
        st.write("### –°–≤–æ–¥–∫–∞ –ø–æ –≥–æ–¥–∞–º:")
        st.write(summary_by_year)

def update_data_page(conn, analyzer):
    st.header("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    update_mode = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:", ["–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV", "API price"])

    if update_mode == "–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV":
        csv_upload_mode = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∑–∞–≥—Ä—É–∑–∫–∏ CSV:", ["–ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (Bulk)", "–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞"])
        if "csv_data" not in st.session_state:
            st.session_state.csv_data = None
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type="csv")
        if uploaded_file is not None:
            st.session_state.csv_data = uploaded_file
        if st.session_state.csv_data is not None:
            try:
                st.session_state.csv_data.seek(0)
                df_csv = pd.read_csv(st.session_state.csv_data, encoding="utf-8-sig")
                df_csv.columns = df_csv.columns.str.strip()
                st.write("–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:", df_csv.columns.tolist())
                if "Contract Code" not in df_csv.columns:
                    st.error("–°—Ç–æ–ª–±–µ—Ü 'Contract Code' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                else:
                    st.write("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä CSV (5 —Å—Ç—Ä–æ–∫):", df_csv.head())
                    st.write("–†–∞–∑–º–µ—Ä DataFrame:", df_csv.shape)
                    st.session_state.csv_data.seek(0)
                    if csv_upload_mode == "–ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (Bulk)":
                        bulk_populate_database_from_csv(st.session_state.csv_data, conn)
                        st.success("–ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                    else:
                        incremental_populate_database_from_csv(st.session_state.csv_data, conn)
                        st.success("–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV: {e}")
        else:
            st.info("–û–∂–∏–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞.")

    elif update_mode == "API price":
        st.write("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Tinkoff API –¥–ª—è —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ –±–∞–∑—ã.")
        api_update_mode = st.radio("–¢–∏–ø –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:", ["–ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "–¢–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç)"], horizontal=True)
        full_update = (api_update_mode == "–ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")

        # –ö–Ω–æ–ø–∫–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–µ–π—á–∞—Å (API price)"):
            with st.spinner("–ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è..."):
                logs = run_api_update_job(full_update=full_update)
            st.success("–ì–æ—Ç–æ–≤–æ!")
            for m in logs:
                st.write("‚Ä¢", m)

        # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        try:
            sched = init_daily_scheduler()
            st.markdown("### –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 00:00, Europe/Stockholm)")
            state = sched["get_state"]()
            st.write("–°–ª–µ–¥—É—é—â–∏–π –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫:", state["next_run"])
            st.write("–ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫:", state["last_run"])
        except Exception as e:
            st.info(f"–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {e}")

def charts_page(conn):
    st.header("–ì—Ä–∞—Ñ–∏–∫–∏")
    data = database.load_data_from_db(conn)
    data_daily = database.load_daily_data_from_db(conn)
    if data.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±–Ω–æ–≤–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        return

    view_option = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞:", ["–ì—Ä–∞—Ñ–∏–∫ –ø–æ –¥–∞—Ç–µ", "–ì—Ä–∞—Ñ–∏–∫ –ø–æ —Ç–∏–∫–µ—Ä—É"])
    daily_sums = data.groupby('date')[['value1', 'value2', 'value3', 'value4']].sum()
    st.dataframe(daily_sums)
    st.subheader("–ì—Ä–∞—Ñ–∏–∫ —Å—É–º–º –ø–æ –¥–Ω—è–º")

    if plt is None:
        st.warning("matplotlib –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –≥—Ä–∞—Ñ–∏–∫–∏ matplotlib –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
    else:
        fig, ax = plt.subplots(figsize=(10, 5))
        for column in ['value1', 'value2', 'value3', 'value4']:
            ax.plot(daily_sums.index, daily_sums[column], marker='o', label=column)
        ax.set_title("–°—É–º–º—ã –ø–æ –¥–Ω—è–º –¥–ª—è value1 - value4")
        ax.set_xlabel("–î–∞—Ç–∞")
        ax.set_ylabel("–°—É–º–º–∞")
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)

    if view_option == "–ì—Ä–∞—Ñ–∏–∫ –ø–æ –¥–∞—Ç–µ":
        unique_dates = sorted(data["date"].unique(), reverse=True)
        selected_date = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É", unique_dates)
        st.subheader("–ì—Ä–∞—Ñ–∏–∫ –ø–æ –¥–∞—Ç–µ")
        df = pd.DataFrame(data)
        filtered_df = df[df['date'] == selected_date]
        filtered_df_1 = filtered_df[filtered_df["metric_type"] == "–ò–∑–º–µ–Ω–µ–Ω–∏–µ"]
        filtered_df_2 = filtered_df[filtered_df["metric_type"] == "–û—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏"]
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(filtered_df_1)
        with col2:
            st.dataframe(filtered_df_2)
        fig = plot_daily_analysis(data, selected_date)
        if fig is not None:
            st.pyplot(fig)
    elif view_option == "–ì—Ä–∞—Ñ–∏–∫ –ø–æ —Ç–∏–∫–µ—Ä—É":
        tickers = data["contract_code"].unique()
        selected_ticker = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–∫–µ—Ä", tickers)
        filtered_df = data[data['contract_code'] == selected_ticker]
        filtered_df_1 = filtered_df[filtered_df["metric_type"] == "–ò–∑–º–µ–Ω–µ–Ω–∏–µ"]
        filtered_df_2 = filtered_df[filtered_df["metric_type"] == "–û—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏"]
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(filtered_df_1)
        with col2:
            st.dataframe(filtered_df_2)
        st.subheader("–ì—Ä–∞—Ñ–∏–∫ –ø–æ —Ç–∏–∫–µ—Ä—É")
        fig = plot_stock_analysis(data, selected_ticker)
        if fig is not None:
            st.pyplot(fig)

def countPosition(conn):
    data = database.load_data_from_db(conn)
    df = pd.DataFrame(data)
    if df.empty:
        return {}
    df['date'] = pd.to_datetime(df['date'])
    last_date = df['date'].max()
    df_last = df[df['date'] == last_date]
    sums = df_last[['value1', 'value2', 'value3', 'value4']].sum()
    return sums

def main():
    # –û—Ç–∫—Ä–æ–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î
    try:
        conn = open_database_connection()
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –ë–î: {e}")
        return

    # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã (–µ—Å–ª–∏ –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è)
    try:
        if hasattr(database, "create_tables"):
            database.create_tables(conn)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ create_tables: %s", e)

    # –ü–æ–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ë–î –≤ sidebar
    try:
        from database import DB_PATH
        st.sidebar.write("DB path:", DB_PATH)
        try:
            st.sidebar.write("DB size (bytes):", os.path.getsize(DB_PATH))
        except Exception:
            st.sidebar.write("DB: –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω")
    except Exception:
        pass

    api_key = _read_api_key()
    if not api_key:
        st.warning("TINKOFF API key not found ‚Äî Tinkoff calls will be disabled. Set st.secrets['TINKOFF_API_KEY'] or env TINKOFF_API_KEY.")
    analyzer = StockAnalyzer(api_key, db_conn=conn)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ–¥–∏–Ω —Ä–∞–∑ (—Ä–µ—Å—É—Ä—Å –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å)
    sched = init_daily_scheduler()
    st.sidebar.markdown("### –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 00:00)")
    st.sidebar.write("–°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫:", sched["get_state"]()["next_run"])
    st.sidebar.write("–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫:", sched["get_state"]()["last_run"])

    st.sidebar.header("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    navigation = st.sidebar.radio("–ü–µ—Ä–µ–π—Ç–∏ –∫", ["–ì–ª–∞–≤–Ω–∞—è", "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö", "–ì—Ä–∞—Ñ–∏–∫–∏", "DB health"])
    if navigation == "–ì–ª–∞–≤–Ω–∞—è":
        main_page(conn, analyzer, api_key)
    elif navigation == "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö":
        update_data_page(conn, analyzer)
    elif navigation == "–ì—Ä–∞—Ñ–∏–∫–∏":
        charts_page(conn)
    elif navigation == "DB health":
        db_health_check(conn)

    try:
        st.sidebar.bar_chart(countPosition(conn))
    except Exception:
        st.sidebar.info("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ–∑–∏—Ü–∏–∏ (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö).")

    conn.close()

if __name__ == "__main__":
    main()
