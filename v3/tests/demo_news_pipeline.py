#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è News Pipeline
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import json
import logging
import tempfile
from pathlib import Path
from typing import List

from core.news_pipeline import (
    BatchMode,
    NewsBatchProcessor,
    PipelineConfig,
    PipelineRequest,
    load_pipeline_config,
)
from core.news_pipeline.models import NewsItem, TickerRecord
from core.news_pipeline.repository import NewsPipelineRepository

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_test_data() -> List[NewsItem]:
    """–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–µ–π."""
    return [
        NewsItem(
            id=1,
            title="–°–±–µ—Ä–±–∞–Ω–∫ –æ–±—ä—è–≤–∏–ª –æ –Ω–æ–≤—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –¥–ª—è –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞",
            url="https://example.com/sber-news-1",
            published_at="2025-01-01T10:00:00Z",
            body="–°–±–µ—Ä–±–∞–Ω–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª –Ω–æ–≤—ã–µ –∫—Ä–µ–¥–∏—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –¥–ª—è –º–∞–ª–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –±–∏–∑–Ω–µ—Å–∞...",
            source="–†–ë–ö"
        ),
        NewsItem(
            id=2,
            title="–ì–∞–∑–ø—Ä–æ–º —É–≤–µ–ª–∏—á–∏–ª –¥–æ–±—ã—á—É –≥–∞–∑–∞ –Ω–∞ 15%",
            url="https://example.com/gazp-news-1",
            published_at="2025-01-01T11:00:00Z",
            body="–ì–∞–∑–ø—Ä–æ–º —Å–æ–æ–±—â–∏–ª –æ–± —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –¥–æ–±—ã—á–∏ –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ –≥–∞–∑–∞...",
            source="–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å"
        ),
        NewsItem(
            id=3,
            title="–õ—É–∫–æ–π–ª –æ—Ç–∫—Ä—ã–ª –Ω–æ–≤–æ–µ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–µ –≤ –°–∏–±–∏—Ä–∏",
            url="https://example.com/lkoh-news-1",
            published_at="2025-01-01T12:00:00Z",
            body="–õ—É–∫–æ–π–ª –æ–±—ä—è–≤–∏–ª –æ–± –æ—Ç–∫—Ä—ã—Ç–∏–∏ –Ω–æ–≤–æ–≥–æ –Ω–µ—Ñ—Ç—è–Ω–æ–≥–æ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏—è...",
            source="–¢–ê–°–°"
        ),
        NewsItem(
            id=4,
            title="–ú–¢–° –∑–∞–ø—É—Å—Ç–∏–ª 5G —Å–µ—Ç—å –≤ –ú–æ—Å–∫–≤–µ",
            url="https://example.com/mts-news-1",
            published_at="2025-01-01T13:00:00Z",
            body="–ú–¢–° –æ–±—ä—è–≤–∏–ª –æ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ç–∏ 5G –≤ —Å—Ç–æ–ª–∏—Ü–µ...",
            source="–í–µ–¥–æ–º–æ—Å—Ç–∏"
        ),
        NewsItem(
            id=5,
            title="–Ø–Ω–¥–µ–∫—Å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞",
            url="https://example.com/yandex-news-1",
            published_at="2025-01-01T14:00:00Z",
            body="–Ø–Ω–¥–µ–∫—Å –∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø–æ–∏—Å–∫–∞...",
            source="–•–∞–±—Ä–∞—Ö–∞–±—Ä"
        )
    ]


def create_test_tickers() -> List[TickerRecord]:
    """–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–∏–∫–µ—Ä—ã."""
    return [
        TickerRecord(
            id=1,
            ticker="SBER",
            name="–°–±–µ—Ä–±–∞–Ω–∫",
            aliases=["–°–±–µ—Ä–±–∞–Ω–∫", "–°–±–µ—Ä", "SBER", "–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫"],
            exchange="MOEX",
            description="–ö—Ä—É–ø–Ω–µ–π—à–∏–π –±–∞–Ω–∫ –†–æ—Å—Å–∏–∏"
        ),
        TickerRecord(
            id=2,
            ticker="GAZP",
            name="–ì–∞–∑–ø—Ä–æ–º",
            aliases=["–ì–∞–∑–ø—Ä–æ–º", "GAZP", "–ü–ê–û –ì–∞–∑–ø—Ä–æ–º"],
            exchange="MOEX",
            description="–ö—Ä—É–ø–Ω–µ–π—à–∞—è –≥–∞–∑–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è –†–æ—Å—Å–∏–∏"
        ),
        TickerRecord(
            id=3,
            ticker="LKOH",
            name="–õ—É–∫–æ–π–ª",
            aliases=["–õ—É–∫–æ–π–ª", "LKOH", "–ü–ê–û –õ—É–∫–æ–π–ª"],
            exchange="MOEX",
            description="–ö—Ä—É–ø–Ω–µ–π—à–∞—è –Ω–µ—Ñ—Ç—è–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è –†–æ—Å—Å–∏–∏"
        ),
        TickerRecord(
            id=4,
            ticker="MTSS",
            name="–ú–¢–°",
            aliases=["–ú–¢–°", "MTSS", "–ü–ê–û –ú–¢–°"],
            exchange="MOEX",
            description="–ö—Ä—É–ø–Ω–µ–π—à–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä —Å–≤—è–∑–∏ –†–æ—Å—Å–∏–∏"
        ),
        TickerRecord(
            id=5,
            ticker="YNDX",
            name="–Ø–Ω–¥–µ–∫—Å",
            aliases=["–Ø–Ω–¥–µ–∫—Å", "YNDX", "Yandex"],
            exchange="NASDAQ",
            description="–ö—Ä—É–ø–Ω–µ–π—à–∞—è IT –∫–æ–º–ø–∞–Ω–∏—è –†–æ—Å—Å–∏–∏"
        )
    ]


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è News Pipeline")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_db:
        db_path = tmp_db.name
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
        print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
        repository = NewsPipelineRepository(db_path)
        repository.ensure_schema()
        print("‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        print("\nüì∞ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        news_items = create_test_data()
        for item in news_items:
            repository.insert_article(item)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–∏–∫–µ—Ä—ã
        print("\nüè∑Ô∏è  –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤...")
        tickers = create_test_tickers()
        for ticker in tickers:
            repository.insert_ticker(ticker)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(tickers)} —Ç–∏–∫–µ—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        print("\n‚öôÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        config = PipelineConfig(
            batch_size=10,
            chunk_size=5,
            auto_apply_threshold=0.85,
            review_lower_threshold=0.60,
            fuzzy_threshold=65,
            cos_candidate_threshold=0.60,
            cos_auto_threshold=0.80,
            embedding_model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            use_faiss=False,
            cache_embeddings=True,
            auto_apply_confirm=True
        )
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...")
        processor = NewsBatchProcessor(repository)
        processor.initialize(config)
        print("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–æ–∑–¥–∞–Ω –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
        print("\nüìã –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        request = PipelineRequest(
            mode=BatchMode.ONLY_UNPROCESSED,
            batch_size=10,
            chunk_size=5
        )
        print("‚úÖ –ó–∞–ø—Ä–æ—Å —Å–æ–∑–¥–∞–Ω")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        print("\nüöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        result = processor.process_batch(request)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"   - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {result.processed_count}")
        print(f"   - –°–æ–∑–¥–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {result.candidates_count}")
        print(f"   - –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time:.2f} —Å–µ–∫")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        print("\nüîç –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
        candidates = repository.fetch_pending_candidates(limit=10)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        if candidates:
            print("\nüìä –ü—Ä–∏–º–µ—Ä—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
            for i, candidate in enumerate(candidates[:3], 1):
                print(f"   {i}. {candidate.ticker} - {candidate.score:.3f} ({candidate.method})")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
        with repository.connect() as conn:
            articles_count = conn.execute("SELECT COUNT(*) FROM articles").fetchone()[0]
            tickers_count = conn.execute("SELECT COUNT(*) FROM tickers").fetchone()[0]
            candidates_count = conn.execute("SELECT COUNT(*) FROM news_tickers").fetchone()[0]
            confirmed_count = conn.execute("SELECT COUNT(*) FROM news_tickers WHERE confirmed = 1").fetchone()[0]
            
            print(f"   - –°—Ç–∞—Ç–µ–π: {articles_count}")
            print(f"   - –¢–∏–∫–µ—Ä–æ–≤: {tickers_count}")
            print(f"   - –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {candidates_count}")
            print(f"   - –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö: {confirmed_count}")
        
        print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {db_path}")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            Path(db_path).unlink()
        except:
            pass


if __name__ == "__main__":
    main()
