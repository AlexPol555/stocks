from __future__ import annotations

from datetime import date, datetime, time, timezone
from typing import Any, Dict, List

from core.bootstrap import setup_environment

setup_environment()

import time as pytime

import streamlit as st

from core import news, ui


@st.cache_data(ttl=60)
def _load_articles(limit: int) -> List[Dict[str, Any]]:
    return news.fetch_recent_articles(limit=limit)


@st.cache_data(ttl=120)
def _load_sources() -> List[Dict[str, Any]]:
    return news.fetch_sources()


@st.cache_data(ttl=120)
def _load_jobs(limit: int) -> List[Dict[str, Any]]:
    return news.fetch_jobs(limit=limit)


ui.page_header(
    "–ù–æ–≤–æ—Å—Ç–∏",
    "–°–æ–±–∏—Ä–∞–µ–º RSS-–ª–µ–Ω—Ç—ã –∏ –≤—ã–¥–µ–ª—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–∏–∫–µ—Ä–æ–≤ –∑–∞ –ø—Ä–æ—à–µ–¥—à–∏–π –¥–µ–Ω—å.",
    icon="üóûÔ∏è",
)

news.ensure_schema()

control_col, summary_col = st.columns((2, 1))
with control_col:
    if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–µ—Ä —Å–µ–π—á–∞—Å", use_container_width=True):
        progress_placeholder = st.empty()
        progress_bar = st.progress(0)

        state = {
            "start": None,
            "total_sources": 0,
            "article_totals": {},
            "article_total": 0,
            "articles_done": 0,
            "matching_total": 0,
            "matching_done": 0,
            "current_source": "",
            "logs": [],
            "eta": None,
        }

        def _format_duration(value: float) -> str:
            seconds = int(max(value, 0))
            minutes, sec = divmod(seconds, 60)
            hours, minutes = divmod(minutes, 60)
            if hours:
                return f"{hours:02d}:{minutes:02d}:{sec:02d}"
            return f"{minutes:02d}:{sec:02d}"

        def _log(message: str) -> None:
            state["logs"].append(message)
            state["logs"] = state["logs"][-6:]

        def _render_progress() -> None:
            processed = state["articles_done"] + state["matching_done"]
            total = max(state["article_total"] + state["matching_total"], 1)
            ratio = min(max(processed / total, 0.0), 1.0)
            progress_bar.progress(int(ratio * 100))

            lines: List[str] = []
            if state["current_source"]:
                lines.append(f"**–¢–µ–∫—É—â–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫:** {state['current_source']}")
            if state["article_total"]:
                lines.append(
                    f"–°—Ç–∞—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {state['articles_done']} / {state['article_total']}"
                )
            else:
                lines.append(f"–°—Ç–∞—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {state['articles_done']}")
            if state["matching_total"]:
                lines.append(
                    f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∏–∫–µ—Ä–æ–≤: {state['matching_done']} / {state['matching_total']}"
                )
            if state["eta"] is not None and processed < total:
                lines.append(f"–û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: ‚âà {_format_duration(state['eta'])}")
            elif processed >= total and total > 0:
                lines.append("–û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")

            if state["logs"]:
                lines.append("")
                lines.extend(f"‚Ä¢ {entry}" for entry in state["logs"][-5:])

            progress_placeholder.markdown("\n".join(lines) or " ")

        def _progress_callback(stage: str, payload: Dict[str, object]) -> None:
            now = pytime.time()
            if state["start"] is None:
                state["start"] = now

            if stage == "start":
                state["total_sources"] = int(payload.get("total_sources", 0) or 0)
                _log(f"–ó–∞–ø—É—Å–∫: –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ {state['total_sources']}")
            elif stage == "source_start":
                state["current_source"] = str(payload.get("source") or "")
                idx = int(payload.get("index", 0) or 0)
                total = state["total_sources"] or 1
                _log(f"–ò—Å—Ç–æ—á–Ω–∏–∫ {idx}/{total}: {state['current_source']} ‚Äî –ø–æ–ª—É—á–∞–µ–º –ª–µ–Ω—Ç—É")
            elif stage == "source_feed":
                idx = int(payload.get("index", 0) or 0)
                entries = int(payload.get("entries", 0) or 0)
                state["article_totals"][idx] = entries
                state["article_total"] = sum(state["article_totals"].values())
                _log(
                    f"{payload.get('source')}: –∑–∞–ø–∏—Å–µ–π –≤ –ª–µ–Ω—Ç–µ {entries}"
                )
            elif stage == "article_progress":
                state["articles_done"] += 1
                article_total = int(payload.get("article_total", 0) or 0)
                article_index = int(payload.get("article_index", 0) or 0)
                title = str(payload.get("title") or "").strip()
                if article_total <= 5 or article_index == article_total or article_index % 5 == 0:
                    if title:
                        truncated = (title[:57] + "‚Ä¶") if len(title) > 60 else title
                        _log(
                            f"{payload.get('source')}: {article_index}/{article_total} ‚Äî {truncated}"
                        )
                    else:
                        _log(
                            f"{payload.get('source')}: {article_index}/{article_total}"
                        )
            elif stage == "article_skipped":
                article_total = int(payload.get("article_total", 0) or 0)
                article_index = int(payload.get("article_index", 0) or 0)
                reason = str(payload.get("reason") or "–ø—Ä–æ–ø—É—Å–∫")
                _log(
                    f"{payload.get('source')}: {article_index}/{article_total} ‚Äî {reason}"
                )
            elif stage == "source_store":
                _log(
                    f"{payload.get('source')}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {payload.get('new_articles', 0)}, –¥—É–±–ª–µ–π {payload.get('duplicates', 0)}"
                )
            elif stage == "matching_start":
                state["matching_total"] = int(payload.get("total", 0) or 0)
                state["matching_done"] = 0
                if state["matching_total"]:
                    _log(
                        f"–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–∏–∫–µ—Ä—ã: {state['matching_total']} —Å—Ç–∞—Ç–µ–π"
                    )
            elif stage == "matching_progress":
                state["matching_done"] = int(payload.get("processed", 0) or 0)
            elif stage == "complete":
                _log(
                    "–ò—Ç–æ–≥: –Ω–æ–≤—ã—Ö {new}, –¥—É–±–ª–µ–π {dup}, —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π {match}".format(
                        new=payload.get("new_articles", 0),
                        dup=payload.get("duplicates", 0),
                        match=payload.get("ticker_matches", 0),
                    )
                )

            processed = state["articles_done"] + state["matching_done"]
            total = max(state["article_total"] + state["matching_total"], 1)
            if processed > 0 and total:
                elapsed = now - (state["start"] or now)
                estimated_total = elapsed / processed * total
                state["eta"] = max(estimated_total - elapsed, 0.0)
            else:
                state["eta"] = None

            _render_progress()

        with st.spinner("–°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏..."):
            result = news.run_fetch_job(progress_callback=_progress_callback)

        status = result.get("status")
        if status == "success":
            progress_bar.progress(100)
            stats = result.get("stats", {})
            new_articles = stats.get("new_articles", 0)
            duplicates = stats.get("duplicates", 0)
            tickers = stats.get("ticker_matches", 0)
            st.success(
                f"–ì–æ—Ç–æ–≤–æ: –¥–æ–±–∞–≤–ª–µ–Ω–æ {new_articles} —Å—Ç–∞—Ç–µ–π, –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–µ–π {duplicates}, —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Ç–∏–∫–µ—Ä–æ–≤ {tickers}."
            )
            _load_articles.clear()
            _load_sources.clear()
            _load_jobs.clear()
        elif status == "locked":
            progress_bar.empty()
            progress_placeholder.warning("–ü–∞—Ä—Å–µ—Ä —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É –ø–æ–∑–∂–µ.")
        else:
            progress_bar.empty()
            progress_placeholder.error(
                f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.get('error', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
            )

    if st.button("–°–±—Ä–æ—Å–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É", use_container_width=True):
        with st.spinner("–°–±—Ä–∞—Å—ã–≤–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É..."):
            was_locked = news.release_parser_lock()
        if was_locked:
            st.success("–õ–æ–∫ –±—ã–ª —Å–±—Ä–æ—à–µ–Ω. –ú–æ–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—É—Å–∫.")
        else:
            st.info("–õ–æ–∫ —É–∂–µ —Å–≤–æ–±–æ–¥–µ–Ω. –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—É—Å–∫ –¥–æ—Å—Ç—É–ø–µ–Ω.")
        _load_jobs.clear()

with summary_col:
    st.caption("–ò—Å—Ç–æ—á–Ω–∏–∫ —Å–ø–∏—Å–∫–∞ RSS –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤ config/news_parser.json –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

st.divider()

ui.section_title("–°–≤–µ–∂–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", "–ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º")

feed_limit = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π", min_value=5, max_value=100, value=25, step=5)
articles = []
try:
    articles = _load_articles(feed_limit)
except Exception as exc:  # pragma: no cover - UI feedback
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π: {exc}")

if not articles:
    st.info("–í –±–∞–∑–µ –ø–æ–∫–∞ –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞—Ä—Å–µ—Ä, —á—Ç–æ–±—ã –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ª–µ–Ω—Ç—É.")
else:
    for article in articles:
        container = st.container()
        title = article.get("title") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
        url = article.get("url")
        meta_parts = []
        if article.get("source"):
            meta_parts.append(article["source"])
        published_at = article.get("published_at")
        if published_at:
            meta_parts.append(str(published_at).replace("T", " "))
        if url:
            container.markdown(f"### [{title}]({url})")
        else:
            container.markdown(f"### {title}")
        if meta_parts:
            container.caption(" ‚Ä¢ ".join(meta_parts))
        tickers = article.get("tickers") or []
        if tickers:
            chips = [(ticker, "info") for ticker in tickers]
            ui.chip_row(chips)
        body = (article.get("body") or "").strip()
        if body:
            snippet = body if len(body) <= 420 else body[:417] + "..."
            container.write(snippet)
        container.divider()

st.divider()

ui.section_title("–°–≤–æ–¥–∫–∞ –∑–∞ –¥–µ–Ω—å", "–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏ —Ç–æ–ø —Ç–∏–∫–µ—Ä–æ–≤")

utc_today = datetime.now(timezone.utc).date()
default_summary_day = utc_today if utc_today > date.min else date.today()
selected_day = st.date_input(
    "–î–∞—Ç–∞ (MSK)",
    value=default_summary_day,
    max_value=utc_today,
    help="–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É, —á—Ç–æ–±—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ–±–∑–æ—Ä –∑–∞ –º–æ—Å–∫–æ–≤—Å–∫–∏–π —Ç–æ—Ä–≥–æ–≤—ã–π –¥–µ–Ω—å",
)

summary_data: Dict[str, Any] | None = None
try:
    target_dt = datetime.combine(selected_day, time.min, tzinfo=timezone.utc)
    summary_data = news.build_summary(target_dt)
except Exception as exc:  # pragma: no cover - UI feedback
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤–æ–¥–∫—É: {exc}")

if summary_data:
    top_mentions = summary_data.get("top_mentions", [])
    if top_mentions:
        mention_table = [[item.get("ticker"), item.get("mentions")] for item in top_mentions]
        st.markdown("**–¢–æ–ø —É–ø–æ–º–∏–Ω–∞–Ω–∏–π:**")
        st.table({"–¢–∏–∫–µ—Ä": [row[0] for row in mention_table], "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": [row[1] for row in mention_table]})
    else:
        st.caption("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–µ–Ω—å –Ω–µ—Ç –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤.")

    clusters = summary_data.get("clusters", [])
    if clusters:
        for cluster in clusters:
            header = cluster.get("headline") or "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"
            sources_count = cluster.get("sources_count", 1)
            extra = f"{sources_count} –∏—Å—Ç–æ—á–Ω–∏–∫–∞" if sources_count != 1 else "1 –∏—Å—Ç–æ—á–Ω–∏–∫"
            st.markdown(f"#### {header}")
            st.caption(extra)
            cluster_tickers = cluster.get("tickers") or []
            if cluster_tickers:
                ui.chip_row([(ticker, "info") for ticker in cluster_tickers])
            summary_text = (cluster.get("summary") or "").strip()
            if summary_text:
                st.write(summary_text)
            links = cluster.get("links") or []
            if links:
                link_items = "\n".join(f"- [{idx + 1}]({link})" for idx, link in enumerate(links))
                st.markdown(link_items)
            st.divider()
    else:
        st.caption("–ö–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–Ω—è.")

st.divider()

sources = []
try:
    sources = _load_sources()
except Exception as exc:  # pragma: no cover - UI feedback
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {exc}")

if sources:
    ui.section_title("–ü–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏", "–∏—Å—Ç–æ—Ä–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
    st.dataframe(
        {
            "–ù–∞–∑–≤–∞–Ω–∏–µ": [row.get("name") for row in sources],
            "RSS": [row.get("rss_url") for row in sources],
            "–°–∞–π—Ç": [row.get("website") for row in sources],
            "–î–æ–±–∞–≤–ª–µ–Ω–æ": [row.get("created_at") for row in sources],
        },
        use_container_width=True,
    )

jobs = []
try:
    jobs = _load_jobs(15)
except Exception as exc:  # pragma: no cover - UI feedback
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—É—Å–∫–æ–≤: {exc}")

if jobs:
    ui.section_title("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—É—Å–∫–æ–≤", "–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã jobs_log")
    st.dataframe(
        {
            "–ù–∞—á–∞—Ç–æ": [row.get("started_at") for row in jobs],
            "–°—Ç–∞—Ç—É—Å": [row.get("status") for row in jobs],
            "–ó–∞–≤–µ—Ä—à–µ–Ω–æ": [row.get("finished_at") for row in jobs],
            "–ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π": [row.get("new_articles") for row in jobs],
            "–î—É–±–ª–∏–∫–∞—Ç–æ–≤": [row.get("duplicates") for row in jobs],
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": [row.get("log") for row in jobs],
        },
        use_container_width=True,
    )

st.caption("–ù–æ–≤–æ—Å—Ç–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.")
